# realfast x EQT: External Deck v3
## Designer-Ready Format

*Companion document: EQT_INTERNAL_BRIEF.md (team alignment, not for distribution)*

**Reading guide:**
- `[ON SLIDE]` = What appears on the slide. Keep these elements visual and sparse.
- `[SPEAKER NOTES]` = What you say out loud. Never put this on the slide.
- `[VISUAL]` = A table, diagram, or graphic element to design.
- `[FOOTNOTE]` = Small attribution text, bottom of slide.

---

## Slide 1 — Title

[ON SLIDE]
One AI execution partner.
273 portfolio companies.
Measurable impact in weeks.

realfast — Portfolio-scale AI execution

[SPEAKER NOTES]
None. Let the slide sit for 3-5 seconds. This is your opening image.

---

## Slide 2 — The Adoption Challenge

[ON SLIDE]
Enterprise AI adoption is consistently lower than ambition.
The reasons are structural.

- Initiatives start too broad — no constrained scope
- AI is deployed as a tool, not embedded in how people work
- ROI is measured against assumptions, not operating metrics
- Hidden complexity erodes payback before value is visible

[FOOTNOTE]
40%+ of agentic AI projects will be canceled by 2027 — Gartner | Only 2% of organisations have deployed AI agents at full scale — Capgemini (April 2025) | Only 20% of EQT investment professionals generate the bulk of AI usage — EQT ThinQ, Q1 2025

[SPEAKER NOTES]
"EQT has declared AI adoption existential. You've built Motherbrain, partnered with OpenAI and Anthropic, hired 40 professionals in EQT Digital, and hosted an AI Summit for 75+ tech leaders across your portfolio. The ambition is clear.

But the industry data is equally clear. Over 40% of agentic AI projects will be canceled by 2027. Only 2% of organisations have deployed AI agents at full scale. And your own published data shows that even within EQT, 20% of investment professionals generate the bulk of AI usage.

The gap between ambition and adoption isn't about capability or intent. It's structural. Initiatives start too broad. AI gets bolted on rather than built into how people actually work. ROI gets measured against assumptions instead of real operating metrics. These are the same barriers across every enterprise we work with. And they're solvable — but they require a different execution model."

---

## Slide 3 — The Execution Gap at Portfolio Scale

[ON SLIDE]
Strategy exists. Execution capacity at scale does not.

[VISUAL — Two-column comparison]

| What EQT Has Built | What's Typically Missing at Portfolio Level |
|---|---|
| AI thesis and mandate | Internal AI engineering capability |
| Motherbrain for prototyping | A mechanism to take prototypes to production |
| EQT Digital for strategic guidance | Hands-on execution that ships in weeks |
| Perficient for digital transformation | Fast, focused AI-specific delivery |
| Foundation model partnerships | People who turn tools into working systems |

[SPEAKER NOTES]
"You've built an impressive AI infrastructure at the firm level — Motherbrain, EQT Digital, the Perficient acquisition, partnerships with OpenAI and Anthropic. The strategy layer is strong.

The question is: how does that translate into AI systems running inside the actual workflows of your portfolio companies? Each company has different systems, different levels of digital maturity, different operational priorities. But the structural barriers to getting AI into production are remarkably consistent.

The bottleneck across most enterprises isn't ideas or technology. It's the last mile — getting an AI system into a real workflow, used by real people, improving a real operating metric. At portfolio scale, that challenge multiplies."

---

## Slide 4 — What We Do

[ON SLIDE]
We are a horizontal AI execution partner.
One proven model, across industries and use cases.

[VISUAL — Three-column framework]

| AUTOMATE | AUGMENT | CONNECT |
|---|---|---|
| Manual work creating backlogs and errors | Decisions made without adequate support | Systems and data that don't talk |
| Extraction, validation, straight-through processing | Scoring, recommendations, draft generation | Cross-system matching, unified views |
| **EBITDA lever:** Cost reduction, throughput | **EBITDA lever:** Revenue quality, decision speed | **EBITDA lever:** Operational efficiency |

[ON SLIDE]
These friction patterns repeat across every industry.
The workflow details change. The underlying barriers are the same.

[SPEAKER NOTES]
"Before we apply AI to anything, we classify why work is slow. Every operational friction falls into one of three categories: work that should be automated, decisions that should be augmented, or systems that need to be connected.

What makes this powerful at portfolio scale is that these patterns repeat across every industry you invest in. A document processing backlog in healthcare is structurally identical to one in compliance services. A decision-latency problem in industrial scheduling is the same class of problem as one in financial underwriting. The workflow details change. The AI execution model doesn't. That's why we work horizontally."

---

## Slide 5 — Why Horizontal Works

[ON SLIDE]
The same friction shows up everywhere.
The industry wrapper changes — the core problem doesn't.

[VISUAL — Matrix grid]

| Friction Pattern | Healthcare | Industrial Services | Tech-Enabled Services | Financial Services |
|---|---|---|---|---|
| Execution backlog | Patient intake | Field service scheduling | Client onboarding | Claims processing |
| Decision latency | Clinical triage | Maintenance scheduling | Pricing and quoting | Underwriting |
| Cost-to-serve | Staff scheduling | Route optimisation | Compliance checking | Reconciliation |
| Data disconnection | Patient records | Asset data across sites | Client data across platforms | Regulatory data |

[ON SLIDE]
One engagement teaches patterns that accelerate the next.
By the third company, we're faster, cheaper, and more accurate.

[SPEAKER NOTES]
"This matrix is the key to why a horizontal model works better than vertical specialists at portfolio scale. Look at any row — the same structural problem appears in every sector. What we learn solving an execution backlog in healthcare directly accelerates how we solve one in industrial services.

By the third portfolio company engagement, we're meaningfully faster and cheaper — because we've already solved the structural problem elsewhere. That's the compounding advantage a horizontal partner delivers that a vertical specialist never can."

---

## Slide 6 — Where We Start

[ON SLIDE]
Not every workflow is worth automating first.
We start where the math works fastest.

[VISUAL — Four selection criteria, each as a card or icon block]

- Direct business metric — something the CFO already tracks
- Repeatable workflow — high frequency = fast proof
- Existing data — no data engineering prerequisite
- Contained blast radius — failure stays local, success is attributable

[ON SLIDE]
Entry points: Execution backlogs | Decision latency | Cost-to-serve pressure | Revenue leakage

[SPEAKER NOTES]
"We're disciplined about where we start. Not every workflow is a good first target. We look for four things: a direct business metric the CFO already tracks, a repeatable workflow with enough volume to generate fast proof, existing data so we're not gated by a data engineering project, and a contained blast radius so that if it doesn't work, it doesn't cascade.

The entry points we're most confident in are execution backlogs — manual processing creating cost and delay; decision-to-execution latency — where the information exists but synthesis is manual; cost-to-serve pressure — where headcount keeps rising just to maintain throughput; and revenue leakage — manual quoting, slow responses, inconsistent pricing.

These aren't limitations. They're the doors that open everything else."

---

## Slide 7 — One Playbook, Every Door

[ON SLIDE]
Same execution model. Regardless of industry, company, or use case.

1. Narrow scope — one workflow, one metric, one team
2. Ship in weeks — production within 3-6 weeks
3. Measure against baseline — before/after on the metric that matters
4. Expand only from proof — next workflow earns its way in

[ON SLIDE]
A repeatable model available to every portfolio company.
Same playbook. Predictable timelines. Predictable costs. Measurable outcomes.

[SPEAKER NOTES]
"This is how we stay horizontal without becoming vague. We don't need to understand your entire business. We need to understand one workflow deeply enough to make it measurably better. Then we move to the next.

For EQT, this means a model you can offer to portfolio companies across your sectors. The portfolio company gets a production AI system. You get a proven value creation lever with predictable costs, timelines, and measurable outcomes."

---

## Slide 8 — What Portfolio Companies Receive

[ON SLIDE]
Tangible outcomes. Not slide decks about AI.

[VISUAL — Four deliverables as cards]

- Production AI system — live, embedded in a real workflow, used by real people
- Measured business impact — before/after on the metric that justified the project
- Operational handover — the company owns and maintains the system
- Expansion roadmap — where to go next, based on proven results

[ON SLIDE]
What the CFO sees: a cost line that dropped, a throughput number that climbed, or a revenue metric that improved — with clear attribution.

[SPEAKER NOTES]
"Every engagement produces four tangible deliverables. A production system that's live and being used. Measured before/after impact on the business metric. Full operational handover so the company owns it. And an expansion roadmap showing where to go next, based on what we've just proved.

What matters for EQT: this creates a repeatable proof point. When the next portfolio company asks 'does AI actually work for businesses like ours?' — you have a measured result from inside your own portfolio to point to."

---

## Slide 9 — The Partnership Model

[ON SLIDE]
How this works at portfolio scale.

[VISUAL — Diagram]

```
                    EQT (Partnership)
                    |
        ┌───────────┼───────────┐
        |           |           |
   Healthcare   Industrials   Services   ...
        |           |           |
   ┌────┴────┐ ┌────┴────┐ ┌────┴────┐
   │realfast │ │realfast │ │realfast │
   │Playbook │ │Playbook │ │Playbook │
   └─────────┘ └─────────┘ └─────────┘
        |           |           |
        └───────────┼───────────┘
                    |
        Cross-Portfolio Intelligence
```

[ON SLIDE]
The flywheel:
1. Select together — identify companies where friction and readiness align
2. We execute — same playbook, adapted to the workflow
3. Results feed back — patterns, benchmarks, proven use cases
4. Deploy to the next — each engagement accelerates the one after it

[SPEAKER NOTES]
"This is the model. We work together to identify portfolio companies where operational friction and readiness align. We execute using our standard playbook, adapted to the specific workflow. Results feed back — cross-portfolio pattern recognition, sector benchmarks, proven use cases. And then we deploy to the next company, where each engagement is faster and more informed because of the one before it.

What makes this compound over time: every engagement deepens the pattern recognition across the portfolio. This builds a cross-portfolio intelligence layer — benchmarks, proven use cases, sector-specific refinements — that gets more valuable with every deployment. That's a moat for both of us."

---

## Slide 10 — The Economics

[ON SLIDE]
Phase model designed for PE risk appetite.

[VISUAL — Phase table]

| Phase | What Happens | Investment | Timeline |
|---|---|---|---|
| Prove | 1 company, 1 workflow | $50-150K | 3-6 weeks |
| Validate | 2-3 companies, cross-sector | $150-400K | 6-12 weeks |
| Scale | Cross-portfolio deployment | Framework pricing | Ongoing |

[ON SLIDE]
Illustrative fund-level math:
10 companies x 3% EBITDA improvement x EUR 50M avg EBITDA x 15x exit multiple
= EUR 225M incremental value creation
Cost: <EUR 2M | Return: >100x

[FOOTNOTE]
Illustrative. Depends on portfolio company size, sector, and hold period. The ratio of cost-to-test vs. potential value creation is deliberately asymmetric.

[SPEAKER NOTES]
"The phase model is designed for how PE evaluates commitments. Phase 1 is one portfolio company, one workflow, $50 to $150K, 3 to 6 weeks. That's a rounding error on a portfolio company's OpEx. If it works, Phase 2 validates across 2-3 companies in different sectors. If that works, Phase 3 is cross-portfolio deployment on a framework basis.

The fund-level math — and I want to be clear these are illustrative numbers — but assume 10 companies with one engagement each, a conservative 3% EBITDA improvement per company, average EBITDA of EUR 50M, and a 15x exit multiple. That's EUR 225M of incremental value creation. Total cost to get there is under EUR 2M. The ratio of cost-to-test versus potential value creation is deliberately asymmetric. That's the point."

---

## Slide 11 — Why realfast

[ON SLIDE]
Don't take our word for it. Test us.

[VISUAL — Comparison table]

| | realfast | Perficient | Big 4 / SI | Boutique AI |
|---|---|---|---|---|
| Built for | Horizontal portfolio execution | Broad digital transformation | Enterprise advisory | Deep tech R&D |
| Speed | 3-6 weeks | 3-6 months | 6-12 months | Varies |
| Portfolio fit | Same playbook, any industry | Engagement by engagement | Engagement by engagement | Narrow |
| Learning | Compounds cross-portfolio | Standalone | Standalone | No portfolio view |
| Teams | Senior engineers, small | Mixed seniority, large | Junior-heavy, large | Research |
| Pricing | Outcome-anchored | T&M, scope grows | T&M, scope grows | Project |

[ON SLIDE]
Rather than debate it, let's prove it.
Pick a portfolio company. Pick a workflow. Run us alongside your existing options.
Same problem. Same timeline. Compare the output.

[SPEAKER NOTES]
"You've invested heavily in Perficient and that's the right call for large digital programs. We think we're the right call for fast, focused AI execution. But rather than debate the difference, let's demonstrate it.

Pick a portfolio company. Pick a workflow. Run us alongside your existing options — same problem, same timeline. Compare the output on speed, cost, adoption, and measured impact. We're confident enough to invite the comparison."

---

## Slide 12 — How It Starts

[ON SLIDE]
One decision. One company. One workflow.

1. Joint selection — identify a company based on friction and readiness
2. Scoping call — 1 hour. One workflow, one metric, success criteria.
3. Discovery sprint — 2 weeks. Map workflow, establish baseline, design mechanism.
4. Build + deploy — 3-4 weeks. Production system with real users.
5. Measure + decide — hard numbers. Expand, or stop.

[ON SLIDE]
5-6 weeks from handshake to measured impact.

[SPEAKER NOTES]
"The engagement starts with one joint decision — which portfolio company, which workflow. A one-hour scoping call to define the metric and success criteria. Then a two-week discovery sprint to map the workflow, establish a baseline, and design the AI mechanism. Three to four weeks of build and deploy. And then we measure.

Total elapsed time: 5-6 weeks from handshake to measured impact. After Phase 1, the conversation changes from 'will this work?' to 'where do we deploy next?'"

---

## Slide 13 — Close

[ON SLIDE]
Enterprise AI adoption is held back by structural execution barriers — not by ambition or technology.

A portfolio of 273+ companies represents both the challenge and the opportunity.

That starts with one conversation.

[SPEAKER NOTES]
Let this slide breathe. Pause. Then: "We'd like to explore what a Phase 1 engagement could look like with one of your portfolio companies. One conversation to see if the fit is there."

---

# APPENDIX: TALKING POINTS BY AUDIENCE

*These are NOT slides. These are preparation notes for who's in the room.*

## For EQT Partners / Investment Committee

**Lead with:** "The industry data is clear — the gap between AI ambition and AI execution is the defining problem. Your portfolio companies face the same structural barriers every enterprise does: initiatives start too broad, AI gets bolted on rather than built in, and there's no baseline to prove ROI. A horizontal execution partner with a repeatable playbook can systematically address that across the portfolio. The cost to prove it is <$150K. The potential value across even 10 companies is measured in hundreds of millions."

**Partnership frame:** "Think of us the way you think about operational advisors in your industrial network. You don't have 600 advisors on payroll — you have a network you deploy. We're proposing the AI execution equivalent."

**If Perficient comes up:** "Perficient is the right investment for broad digital transformation. What we do is narrower, faster, and cheaper for a specific class of problem. Rather than debate it, let's demonstrate it. Run us on the same problem, same timeline."

## For Sven Tornkvist / Petter Weiderholm (EQT Digital)

**Lead with:** "We're not here to do what you do — we don't do strategy, digital maturity, or technology selection. We do one thing: take a specific workflow inside a portfolio company and put an AI system into production around it in 5-6 weeks, measured against a real operating metric. We think there's an opportunity to work together across the portfolio."

**If Perficient comes up:** "Happy to run side by side. Same problem, same timeline. We think the results show different tools for different jobs."

**Cross-sector question:** "The friction patterns are structurally similar across sectors. A document processing backlog in healthcare is the same class of problem as one in compliance services. The workflow wrapper changes. The execution model doesn't."

## For Portfolio Company CEOs

**Lead with:** "EQT has introduced us to help your team get one AI system into production — targeting a workflow that's creating cost or delays. 5-6 week engagement. We pick one workflow together, measure where it is today, build an AI system around it, and measure the after. You keep the system."

**If bad AI experiences:** "Most AI initiatives stall for the same reason: too broad, not anchored to a specific operating metric, and bolted on to an existing process rather than built into how people actually work. We do it differently — one narrow workflow, one number the CFO already tracks, embedded in the way your team already operates."

---

# VERIFIED SOURCE DATA

| Metric | Source | Verified |
|---|---|---|
| EQT AUM: EUR 270B | EQT Year-End Report 2025 | Yes |
| Portfolio: 273+ companies | EQT website | Yes |
| EQT Digital: ~40 professionals | EQT publications | Yes |
| 20% of investment professionals generate bulk of AI usage | Tornkvist & Weiderholm, EQT ThinQ, Q1 2025. Exact: "only 20 percent of investment professional users represent the lion's share of AI-connected prompts during Q1 2025" | Yes |
| 40%+ agentic AI projects canceled by 2027 | Gartner, cited in EQT ThinQ "Taking AI From Pilot to Production Scale" | Yes |
| 2% of orgs deployed AI agents at full scale | Capgemini survey (April 2025), cited in same EQT ThinQ article | Yes |
| Perficient acquisition: $3B (Oct 2024) | Press release | Yes |
| 94% of exit value from operational improvement | EQT publications | Yes |
| EQT Industrial Network: 600+ advisors | EQT website | Yes |
| EQT X fund: EUR 22B | EQT filings | Yes |
